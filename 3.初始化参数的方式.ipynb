{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cbb066bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=10, bias=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from functions import get_loader, get_model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "_, _, loader = get_loader()\n",
    "model, _, _ = get_model()\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f54982ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,700 || all params: 251,255,080 || trainable%: 0.0030646146537614285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): Linear(\n",
       "    (base_layer): Linear(in_features=768, out_features=10, bias=True)\n",
       "    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 10x1])\n",
       "  )\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): Linear(\n",
       "      (base_layer): Linear(in_features=768, out_features=10, bias=True)\n",
       "      (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 10x1])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, LoftQConfig\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['classifier'],\n",
    "\n",
    "    #设置A层参数初始化方式,默认A层是凯明均匀分布,B层是全0\n",
    "    #init_lora_weights='gaussian',\n",
    "\n",
    "    #使用loftq初始化参数,一般会获得更好的效果\n",
    "    init_lora_weights='loftq',\n",
    "    loftq_config=LoftQConfig(loftq_bits=4),\n",
    "\n",
    "    #使用数值缩放,也是增进训练效果的\n",
    "    use_rslora=True,\n",
    "\n",
    "    #另一种插入层的结构,和loftq不共存\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "#适用于CAUSAL_LM任务的配置\n",
    "#from peft import PromptEncoderConfig\n",
    "#config = PromptEncoderConfig(task_type='CAUSAL_LM', num_virtual_tokens=20, encoder_hidden_size=128)\n",
    "\n",
    "#IA3是比lora更激进的方式,可训练的参数更少\n",
    "#from peft import IA3Config\n",
    "#config = IA3Config(task_type='SEQ_CLS', target_modules=['classifier'])\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e270a4d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62 2.2574074268341064 0.15625\n",
      "1 62 2.2835590839385986 0.125\n",
      "2 62 2.265936851501465 0.125\n",
      "3 62 2.256568670272827 0.125\n",
      "4 62 2.2342605590820312 0.125\n",
      "5 62 2.2471179962158203 0.15625\n",
      "6 62 2.2529959678649902 0.09375\n",
      "7 62 2.2177746295928955 0.09375\n",
      "8 62 2.17441725730896 0.1875\n",
      "9 62 2.1450140476226807 0.25\n",
      "10 62 2.1880834102630615 0.28125\n",
      "11 62 2.166544198989868 0.1875\n",
      "12 62 2.2038490772247314 0.0625\n",
      "13 62 2.118818521499634 0.34375\n",
      "14 62 2.136948347091675 0.3125\n",
      "15 62 2.128154993057251 0.28125\n",
      "16 62 2.189143419265747 0.28125\n",
      "17 62 2.163454532623291 0.21875\n",
      "18 62 2.1524388790130615 0.21875\n",
      "19 62 2.2027273178100586 0.25\n",
      "20 62 2.018207550048828 0.46875\n",
      "21 62 2.075979232788086 0.40625\n",
      "22 62 2.0548763275146484 0.46875\n",
      "23 62 2.042815685272217 0.5\n",
      "24 62 2.10168194770813 0.3125\n",
      "25 62 2.0754051208496094 0.34375\n",
      "26 62 1.9900621175765991 0.625\n",
      "27 62 2.017026424407959 0.53125\n",
      "28 62 2.044901132583618 0.46875\n",
      "29 62 2.0529961585998535 0.375\n",
      "30 62 1.984081745147705 0.71875\n",
      "31 62 2.0559780597686768 0.375\n",
      "32 62 1.9703071117401123 0.59375\n",
      "33 62 1.9662941694259644 0.53125\n",
      "34 62 1.9536776542663574 0.71875\n",
      "35 62 2.0094058513641357 0.5\n",
      "36 62 1.9633032083511353 0.65625\n",
      "37 62 1.9497109651565552 0.625\n",
      "38 62 1.9211204051971436 0.65625\n",
      "39 62 1.9570562839508057 0.6875\n",
      "40 62 1.8995616436004639 0.75\n",
      "41 62 1.9275438785552979 0.71875\n",
      "42 62 1.9006119966506958 0.78125\n",
      "43 62 1.9265389442443848 0.78125\n",
      "44 62 1.9070340394973755 0.6875\n",
      "45 62 1.8529132604599 0.84375\n",
      "46 62 1.8897616863250732 0.6875\n",
      "47 62 1.8428908586502075 0.6875\n",
      "48 62 1.893797755241394 0.71875\n",
      "49 62 1.8372652530670166 0.6875\n",
      "50 62 1.8335775136947632 0.84375\n",
      "51 62 1.814579963684082 0.84375\n",
      "52 62 1.8969275951385498 0.625\n",
      "53 62 1.7657310962677002 0.8125\n",
      "54 62 1.8056144714355469 0.90625\n",
      "55 62 1.8189479112625122 0.8125\n",
      "56 62 1.8273338079452515 0.71875\n",
      "57 62 1.7935847043991089 0.84375\n",
      "58 62 1.821847915649414 0.84375\n",
      "59 62 1.7181426286697388 0.9375\n",
      "60 62 1.7406177520751953 0.9375\n",
      "61 62 1.7755725383758545 0.90625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=11, microseconds=527618)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "#正常训练\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "model.to(device)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "for i, data in enumerate(loader):\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(device)\n",
    "    out = model(**data)\n",
    "    out.loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        labels = data['labels']\n",
    "        logits = out['logits'].argmax(1)\n",
    "        acc = (labels == logits).sum().item() / len(labels)\n",
    "\n",
    "        print(i, len(loader), out.loss.item(), acc)\n",
    "\n",
    "datetime.datetime.now() - now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
