{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53ce9fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=768, out_features=10, bias=True)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from functions import get_loader, get_model\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "_, _, loader = get_loader()\n",
    "model, _, _ = get_model()\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0dd067d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 7,700 || all params: 251,255,080 || trainable%: 0.0030646146537614285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ModulesToSaveWrapper(\n",
       "  (original_module): Linear(\n",
       "    (base_layer): Linear(in_features=768, out_features=10, bias=True)\n",
       "    (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 10x1])\n",
       "  )\n",
       "  (modules_to_save): ModuleDict(\n",
       "    (default): Linear(\n",
       "      (base_layer): Linear(in_features=768, out_features=10, bias=True)\n",
       "      (ia3_l): ParameterDict(  (default): Parameter containing: [torch.FloatTensor of size 10x1])\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from peft import LoraConfig, TaskType, get_peft_model, LoftQConfig, PromptEncoderConfig, IA3Config\n",
    "\n",
    "config = LoraConfig(\n",
    "    task_type=TaskType.SEQ_CLS,\n",
    "    inference_mode=False,\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=['classifier'],\n",
    "\n",
    "    #设置A层参数初始化方式,默认A层是凯明均匀分布,B层是全0\n",
    "    #init_lora_weights='gaussian',\n",
    "\n",
    "    #使用loftq初始化参数,一般会获得更好的效果\n",
    "    init_lora_weights='loftq',\n",
    "    loftq_config=LoftQConfig(loftq_bits=4),\n",
    "\n",
    "    #使用数值缩放,也是增进训练效果的\n",
    "    use_rslora=True,\n",
    "\n",
    "    #另一种插入层的结构,和loftq不共存\n",
    "    use_dora=False,\n",
    ")\n",
    "\n",
    "#适用于CAUSAL_LM任务的配置\n",
    "config = PromptEncoderConfig(task_type='SEQ_CLS',\n",
    "                             num_virtual_tokens=20,\n",
    "                             encoder_hidden_size=128)\n",
    "\n",
    "#IA3是比lora更激进的方式,可训练的参数更少\n",
    "config = IA3Config(task_type='SEQ_CLS', target_modules=['classifier'])\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "model.classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "965de7ec",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 62 2.4089834690093994 0.0\n",
      "1 62 2.3106164932250977 0.09375\n",
      "2 62 2.316065788269043 0.0625\n",
      "3 62 2.363997459411621 0.09375\n",
      "4 62 2.301146984100342 0.09375\n",
      "5 62 2.2765536308288574 0.1875\n",
      "6 62 2.3127336502075195 0.0625\n",
      "7 62 2.313250780105591 0.0625\n",
      "8 62 2.263867139816284 0.09375\n",
      "9 62 2.257852554321289 0.03125\n",
      "10 62 2.229757785797119 0.1875\n",
      "11 62 2.2166881561279297 0.1875\n",
      "12 62 2.1789209842681885 0.125\n",
      "13 62 2.2374184131622314 0.1875\n",
      "14 62 2.230839729309082 0.15625\n",
      "15 62 2.2052810192108154 0.125\n",
      "16 62 2.1605560779571533 0.21875\n",
      "17 62 2.1335458755493164 0.25\n",
      "18 62 2.146886110305786 0.1875\n",
      "19 62 2.1742775440216064 0.25\n",
      "20 62 2.192859411239624 0.1875\n",
      "21 62 2.1038081645965576 0.28125\n",
      "22 62 2.1520001888275146 0.25\n",
      "23 62 2.1106300354003906 0.375\n",
      "24 62 2.1247026920318604 0.34375\n",
      "25 62 2.1607823371887207 0.21875\n",
      "26 62 2.1247217655181885 0.15625\n",
      "27 62 2.051104784011841 0.5625\n",
      "28 62 2.0689423084259033 0.46875\n",
      "29 62 2.037259340286255 0.59375\n",
      "30 62 2.0886518955230713 0.4375\n",
      "31 62 2.0399112701416016 0.53125\n",
      "32 62 2.0339131355285645 0.5625\n",
      "33 62 2.0201523303985596 0.59375\n",
      "34 62 2.03676438331604 0.53125\n",
      "35 62 2.012573480606079 0.625\n",
      "36 62 2.0173566341400146 0.625\n",
      "37 62 1.942825198173523 0.75\n",
      "38 62 1.9864193201065063 0.625\n",
      "39 62 1.9341926574707031 0.75\n",
      "40 62 1.9701616764068604 0.625\n",
      "41 62 1.9886361360549927 0.625\n",
      "42 62 1.9486091136932373 0.59375\n",
      "43 62 1.9258460998535156 0.84375\n",
      "44 62 1.9121100902557373 0.78125\n",
      "45 62 1.9130499362945557 0.84375\n",
      "46 62 1.9048962593078613 0.78125\n",
      "47 62 1.887307047843933 0.875\n",
      "48 62 1.9133539199829102 0.75\n",
      "49 62 1.8954181671142578 0.8125\n",
      "50 62 1.8833553791046143 0.71875\n",
      "51 62 1.878673791885376 0.90625\n",
      "52 62 1.8301059007644653 0.90625\n",
      "53 62 1.833159327507019 0.90625\n",
      "54 62 1.8676620721817017 0.78125\n",
      "55 62 1.7989805936813354 0.9375\n",
      "56 62 1.8499683141708374 0.84375\n",
      "57 62 1.7384623289108276 1.0\n",
      "58 62 1.8065447807312012 0.96875\n",
      "59 62 1.810263991355896 0.78125\n",
      "60 62 1.8282135725021362 0.84375\n",
      "61 62 1.7763408422470093 0.8125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "datetime.timedelta(seconds=12, microseconds=140622)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "#正常训练\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "model.to(device)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "for i, data in enumerate(loader):\n",
    "    for k, v in data.items():\n",
    "        data[k] = v.to(device)\n",
    "    out = model(**data)\n",
    "    out.loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i % 1 == 0:\n",
    "        labels = data['labels']\n",
    "        logits = out['logits'].argmax(1)\n",
    "        acc = (labels == logits).sum().item() / len(labels)\n",
    "\n",
    "        print(i, len(loader), out.loss.item(), acc)\n",
    "\n",
    "datetime.datetime.now() - now"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cuda117]",
   "language": "python",
   "name": "conda-env-cuda117-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
